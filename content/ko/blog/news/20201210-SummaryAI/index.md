---
date: 2020-12-10
title: "SK텔레콤, 요약 잘하는 AI모델 공개…'자연어이해' 기술 강화"
linkTitle: "SK텔레콤, 요약 잘하는 AI모델 공개…'자연어이해' 기술 강화"
description: "최근 깃허브에 'KoBART' 올려…3번째 AI모델 오픈<br>
페이스북 AI모델 한국어판…'한 줄 요약' 능력 강점<br>
기존 AI기술 기반 생산성 향상·수익사업화 연장선<br>
박정호 대표 'AI빅테크 기업 도약' 추진에 가속도"
author: 임민철 기자
resources:
- src: "**.{png,jpeg}"
  title: "Image #:counter"
  params:
    byline: "아주경제"
---

{{< imgproc kobart Fit "900x600" >}}
[사진=게티이미지뱅크]
{{< /imgproc >}}

SK텔레콤 연구진들이 한국어 뉴스나 문서를 읽고 고품질 요약문을 만들어내는 능력이 뛰어난 인공지능(AI) 언어처리 모델을 조용히 공개했다. 이로써 SK텔레콤은 자연어처리(NLP) 분야 가운데 문장이나 글이 전달하는 의미를 짚는 '자연어이해(NLU·Natural Language Understanding)' 영역 기술력을 강화할 수 있게 됐다.

텍스트 요약 기능은 일반 소비자부터 기업 및 학술단체를 위한 AI에 폭넓게 활용될 수 있다. 지난 7월 출시된 네이버 '보이스뉴스'는 각 언론사가 주요 뉴스로 선정한 기사 요약본을 음성으로 들려 주는 서비스다. 같은달 먼저 출시된 한국과학기술정보연구원(KISTI) 과학정보서비스 '사이언스온'의 논문 요약 AI는 논문 원본에서 주요 내용을 추출해 연구자들이 필요한 논문을 쉽게 찾도록 돕는다.

새 AI 모델 공개는 수년 전부터 지속된 SK텔레콤의 AI 경쟁력 강화 움직임의 연장선에 있다. 박정호 SK텔레콤 대표는 이달초 조직개편 발표와 함께 "AI가 모든 사업의 기반 플랫폼 역할을 할 것"이라고 강조했다. 내년부터 핵심 사업·제품을 중심으로 재편된 조직을 통해 'AI 빅테크 기업'으로 도약하기 위한 전략에 속도를 낼 전망이다.

10일 현재 SK텔레콤 테크(T3K) 센터가 운영하는 깃허브(GitHub) 저장소에는 '코바트(KoBART)'라는 개발 프로젝트의 소스코드가 공개돼 있다. 이는 작년 10월 공개된 '코버트(KoBERT)'와 올해 2월 공개된 '한국어 GPT-2(KoGPT2)'에 이어, SK텔레콤 연구진이 만들어 공개한 세 번째 AI 언어처리 모델이다.

SK텔레콤은 앞서 개발한 KoGPT2를 챗봇의 더 자연스러운 말씨 등을 구현하는 데 활용했다. 이번에 공개된 코바트 역시 SK텔레콤의 AI 경쟁력을 높이기 위해 만들어졌을 것으로 짐작된다. SK텔레콤 관계자는 코바트의 활용방안 문의에 "여러 방안에 대해 검토 중이며 아직 결정된 바 없다"고 답했다. 다만 코바트를 공개한 조직이 T3K 센터라는 점을 힌트로 그 가능성을 짐작해볼 수는 있다.

T3K는 SK텔레콤이 최근 조직개편을 통해 AI 빅테크 기업으로 도약하기 위한 기반 가운데 하나로 내세운 조직이다. SK텔레콤은 T3K가 딥러닝 기반 대화형 AI(한국어 GPT-3)', AI 가속기, 데이터분석플랫폼, 모바일에지컴퓨팅(MEC) 클라우드, 4대 분야 기술 개발에 집중할 것이라고도 밝혔다.

코바트의 활용 범위는 그 원형인 '바트(BART)' 모델의 특징을 바탕으로 추정해볼 수 있다. 바트는 작년 10월말 페이스북 연구진이 학술지 출판 전 논문 수집사이트 '아카이브(arXiv)'에 발표한 논문을 통해 처음 소개된 AI 언어처리 모델이다. 논문에 따르면 이 모델은 텍스트생성, 질의응답(QA), 기계번역(MT), 내용 요약 등 작업에 강점이 있다.

페이스북 연구진은 작년 11월 9일 바트 모델의 소스코드를 깃허브에 공개했다. 이는 영어로 된 텍스트를 다루는 성능은 뛰어나지만 다른 언어 처리 성능은 보장하지 않는다. SK텔레콤 연구진은 이 코드를 활용해 한국어를 처리하면서 품질이 뛰어난 결과물을 얻을 수 있는 모델로 코바트를 개발한 것으로 보인다.

SK텔레콤은 T3K 센터의 깃허브 프로젝트 소개 문구를 통해 "한국어 BART는 (페이스북 연구진이 작성한) 논문에서 사용된 Text Infilling 노이즈 함수를 사용해 40GB 이상의 한국어 텍스트에 대해 학습한 한국어 encoder-decoder 언어 모델"이라고 밝혔다. 현재 이 소스코드와 함께 공개된 요약기능 데모를 통해 한국어 뉴스 원문을 '한 줄 요약'해볼 수 있다.

코바트는 약 2억7500만개 문장 분량의 한국어 텍스트 원문을 활용해 학습했다. 이 데이터는 한국어 위키백과 문장 500만개, 청와대 국민청원에서 재작년 8월 이전 기준으로 만료된 청원 데이터 및 국립국어원이 올해 8월 25일 공개한 '모두의 말뭉치' 데이터(대화·뉴스 등)의 문장 2억7000만개 등 다양하다.

SK텔레콤 연구진은 이 데이터로 3주 동안 1억2400만개 파라미터를 사용해 코바트를 학습시켰다. 그 결과 NSMC 테스트 정확도 90.07%, KorSTS 스피어만 상관계수 평가 81.31점, Question Pair 정확도 93.80%를 기록했다. NSMC는 글을 분석해 내용에 담긴 감정을 분류하는 작업, 나머지는 두 문장의 뜻이 얼마나 비슷한지 평가하는 작업의 성능을 측정한다.

앞서 SK텔레콤은 코버트와 KoGPT2 모델 개발에 필요한 GPU를 아마존웹서비스(AWS) 클라우드로부터 제공받았다. 그런데 이번엔 외부의 지원을 받지 않았다. SK텔레콤 연구진은 코바트 모델 개발을 위해 "내부 GPU 자원을 활용했다"고 밝혔다.

---
> 기사 출처 : https://www.ajunews.com/view/20201210114639936